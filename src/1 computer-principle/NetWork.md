---
title: NetWork
icon: creative
---
## 基础知识

### Pin network queue

"Pin network queue"（固定网络队列）是一种网络优化技术，用于将网络流量绑定到特定的网络队列或核心，以减少处理延迟、提高处理效率和提高网络吞吐量



## 工具

### F-Stack

<https://github.com/F-Stack/f-stack>

## By Pass kernel

### 用户态套接字（User-level Sockets）

使用用户态套接字库（如 DPDK、Netmap、AF_XDP 等），在用户空间实现网络协议栈，绕过内核网络协议栈。用户态套接字允许应用程序直接接触到网络数据包，并自行处理和传递数据。

### 网络设备驱动（Network Device Drivers）

定制高性能的网络设备驱动程序，通过直接与网卡硬件进行交互，绕过内核网络协议栈。这种方法通常需要针对特定的硬件进行开发，以实现自定义的网络协议栈。

### RDMA（Remote Direct Memory Access）

RDMA 是一种远程直接内存访问技术，它允许应用程序直接在远程主机之间进行内存访问，绕过操作系统的协议栈。RDMA 提供了低延迟和高吞吐量的网络通信能力，适用于高性能计算和分布式存储等领域。


### 用户态数据包处理库（User-space Packet Processing Libraries）

使用用户态数据包处理库（如 libpcap、PF_RING、Snabb Switch 等），可以直接在用户空间捕获和处理网络数据包，避免了内核空间和用户空间之间的上下文切换。


### DPDK

DPDK（Data Plane Development Kit）通过以下几种手段来优化网络处理速度：

1. **用户态操作**：DPDK以用户态应用程序的形式运行，避免了操作系统内核和用户空间之间的频繁切换。这样可以减少系统调用的开销，提高网络处理的效率。

2. **零拷贝技术**：DPDK使用零拷贝技术，避免了数据在内核空间和用户空间之间的复制。通过直接内存访问（Direct Memory Access，DMA）和共享内存技术，数据可以直接从网络适配器传输到用户空间的应用程序，或者从应用程序发送到网络适配器，减少了数据复制的开销。

3. **大页内存**：DPDK利用大页内存（Huge Pages）来提高内存访问的效率。相对于传统的小页内存，大页内存具有更大的页大小，可以减少TLB（Translation Lookaside Buffer）缓存的失效，提高内存访问的速度和效率。

4. **高性能驱动程序**：DPDK提供了专用的高性能驱动程序，与支持DPDK的网络适配器配合使用，以最大化网络处理的性能。这些驱动程序通过优化中断处理、队列管理和数据传输等方面的细节，提供了更高的吞吐量和更低的延迟。

5. **多队列支持**：DPDK支持多队列技术，允许多个CPU核心同时处理网络流量。通过在多个队列上进行并行处理，可以提高并发性和负载均衡，并实现更高的网络吞吐量。

6. **CPU亲和性**：DPDK允许将特定的CPU核心与特定的网络队列或任务进行绑定，以提高缓存局部性和减少缓存竞争。这可以通过CPU亲和性配置和任务调度来实现，从而优化网络处理的性能。

